{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GFwqquUc-dMC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP0gtU8N4LAM",
        "outputId": "a89212e1-51be-4f58-fbba-8b0779065c5e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUllfvxa4Seh"
      },
      "source": [
        "!pip install scikit-learn==0.24"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGT4pPF44cXk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# regression model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# metrics packages\n",
        "from sklearn.metrics import make_scorer, mean_absolute_percentage_error, mean_squared_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFwqquUc-dMC"
      },
      "source": [
        "# functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8NME3PT-fI9"
      },
      "source": [
        "def hyper_parameter_search(data, X, baseline_start, baseline_end, regressor):\n",
        "  # get date range for baseline and select data\n",
        "  time_base = pd.date_range(start=baseline_start, end=baseline_end, freq='2MS')\n",
        "  data_base = data[time_base]\n",
        "\n",
        "  # get climate data for baseline and stressor\n",
        "  X_base = X.loc[time_base]\n",
        "\n",
        "  # initialize best params matrix\n",
        "  best_params = pd.DataFrame(index=data_base.index, columns=['params','best_score', 'mape', 'rmse'])\n",
        "\n",
        "  # normalize data\n",
        "  X_base_scaled = scaler.fit_transform(X_base)\n",
        "\n",
        "  # predict consumption during the stressor for each account by Random Forrest Regressor\n",
        "  for i, row in data_base.iterrows():\n",
        "    y = row.array\n",
        "    model = regressor.fit(X_base_scaled, y)\n",
        "    y_pred = model.predict(X_base_scaled)\n",
        "    mape = mean_absolute_percentage_error(y_true=y, y_pred=y_pred)\n",
        "    rmse = mean_squared_error(y_true=y, y_pred=y_pred, squared=False)\n",
        "\n",
        "    best_params.loc[i] = (model.best_params_, model.best_score_,mape, rmse)\n",
        "\n",
        "  return best_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO8ccpp-tfFe"
      },
      "source": [
        "def run_model(data, climate_data, baseline_start, baseline_end, pred_start, pred_end,  best_params):\n",
        "  # get date range for baseline and select data\n",
        "  time_base = pd.date_range(start=baseline_start, end=baseline_end, freq='2MS')\n",
        "  data_base = data[time_base]\n",
        "\n",
        "  # get date range for prediction and select data\n",
        "  time_pred = pd.date_range(start=pred_start, end=pred_end, freq='2MS')\n",
        "  data_pred = data[time_pred]\n",
        "\n",
        "  # get climate data for baseline and stressor\n",
        "  # initialize scaler to normalize features\n",
        "  scaler = MinMaxScaler()\n",
        "  X_base = climate_data.loc[time_base]\n",
        "  X_base_scaled = scaler.fit_transform(X_base)\n",
        "\n",
        "  X_pred = climate_data.loc[time_pred]\n",
        "  X_pred_scaled = scaler.fit_transform(X_pred)\n",
        " \n",
        "\n",
        "  # initialize quantile predictions\n",
        "  quantiles = [0.1, 0.2, 0.5, 0.8, 0.9]\n",
        "  prediction_rf = pd.DataFrame(index=data_base.index, columns=['params', 'q0.1','q0.2', 'q0.5', 'q0.8', 'q0.9', 'y_true', 'date'])\n",
        "\n",
        "  # predict consumption during the stressor for each account by Random Forrest Regressor\n",
        "  for i, row in data_base.iterrows():\n",
        "    y = row.to_numpy()\n",
        "    params = best_params['params'].loc[i]\n",
        "    regressor = RandomForestRegressor(**params)\n",
        "    regressor.fit(X_base_scaled, y)\n",
        "    preds = [rf_quantile(regressor, X_pred_scaled, q) for q in quantiles]\n",
        "    prediction_rf.loc[i] = (params, preds[0], preds[1], preds[2], preds[3], preds[4], data_pred.loc[i], time_base)\n",
        "\n",
        "\n",
        "  return prediction_rf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxlNF7-XuaTx"
      },
      "source": [
        "def rf_quantile(m, X, q):\n",
        "    rf_preds = []\n",
        "    for estimator in m.estimators_:\n",
        "        rf_preds.append(estimator.predict(X))\n",
        "    rf_preds = np.array(rf_preds).transpose()  # One row per record.\n",
        "    return np.percentile(rf_preds, q * 100, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3mcVMor4-4i"
      },
      "source": [
        "# data loading and preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o16OGFP48EG"
      },
      "source": [
        "# load  climatic and employment features\n",
        "features = pd.read_csv('/content/drive/MyDrive/Stanford-TUBerlin/CodePaper/climate_economic_features' , index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmgNfc6c5OEK"
      },
      "source": [
        "# process features\n",
        "features.index= pd.to_datetime(features.index)\n",
        "features['month'] = features.index.month_name()\n",
        "# create binary variable for month\n",
        "X = pd.get_dummies(features, columns = ['month'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX0a5jzy8Xe3"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groups = ['SB', 'SD', 'MB', 'MD']\n",
        "\n",
        "for i in groups:\n",
        "  print(i)\n",
        "  consumption_data = pd.read_pickle('/content/drive/MyDrive/Stanford-TUBerlin/CodePaper/Consumption_Matrices/{}_accounts_actual_usage'.format(i))\n",
        "  best_params = pd.read_pickle('/content/drive/MyDrive/Stanford-TUBerlin/CodePaper/HyperparameterSearch/Hyperparams_{}/best_params_{}'.format(i,i))\n",
        "  #pred = run_model(consumption_data, X, '1/1/2002', '11/1/2007','1/1/2008', '7/1/2020',  best_params)\n",
        "  #pred.to_pickle('/content/drive/MyDrive/Stanford-TUBerlin/CodePaper/RegressionModel/pred_{}'.format(i))\n",
        "  print(best_params.rmse.min(), best_params.rmse.max(), best_params.rmse.mean())\n"
      ],
      "metadata": {
        "id": "VqSl7xOloWOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60380146-d1ae-4b47-a08c-9f899fd89f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SB\n",
            "4.283417534439648 605.0798647496375 65.68149546999275\n",
            "SD\n",
            "2.758927733029219 341.82421807041715 32.57791641956227\n",
            "MB\n",
            "8.715431339652776 2986.20487608477 161.68665257814473\n",
            "MD\n",
            "13.066729599256659 2688.4886489518567 465.69928042273887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi8hrJJdndYh"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}